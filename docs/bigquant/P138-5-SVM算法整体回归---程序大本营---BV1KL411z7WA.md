# P138：5-SVM算法整体回归 - 程序大本营 - BV1KL411z7WA

来最后呢我们还剩15分钟时间，那么我们将咱们支持向量机是吧。

![](img/1f870c914653d09cacfa80c043aaf02e_1.png)

咱们从头我们呢再捋一遍，好不好，让大家呢对于咱们这个算法，加深一下理解和认识，好现在呢你就能够发现啊。



![](img/1f870c914653d09cacfa80c043aaf02e_3.png)

咱们支持向量机叫support vector machine，support呢就是支持的意思，vector就是向量，你可以把这个vector就把它当成数据就好了。



![](img/1f870c914653d09cacfa80c043aaf02e_5.png)

我们支持向量机呢。

![](img/1f870c914653d09cacfa80c043aaf02e_7.png)

咱们再进行分类，或者说进行回归的时候，你看咱们就是希望是吧，以最大的间隔把这个底是吧，给它分开，这个算法呢就特别漂亮，是不是以最大的间隔来分开，那这样的话它就会左右兼顾，这样的话分离效果往往就很好。



![](img/1f870c914653d09cacfa80c043aaf02e_9.png)

那么在神经网络出来之前，这个支持向量机在我们工业界是吧，在互联网当中它风靡了十几20年是吧，它的这个应用呢好处呢这个一直在推广。



![](img/1f870c914653d09cacfa80c043aaf02e_11.png)

经久不息是吧，那这是一个非常经典的算法好。

![](img/1f870c914653d09cacfa80c043aaf02e_13.png)

那么我们到底如何才能够把这个嗯，数据给它分开呢，这到底是怎样的一个原理呢，你能够看咱们二维的这个数据，中间的这条b线是吧，它距离咱们红色的点，距离咱们蓝色的底正好在中间，那这个时候呢我们找分割边界。

咱们的p1 p2 和咱们的p3 ，这个呢就是分割边界是吧，他刚好在临界，这，你我们其他的蓝色的点，是不是都在p3 点的这个左侧，那么我们其他红色的点是不是都在p1 ，p2 点的右侧呀对吧。

那其他的点都好说一分就开了是吧，所以说那这个我们可以这样称呼其他的点儿，它的特征足够明显，你注意我的用词儿，我们叫什么叫特征足够明显，那么它就容易区分姚明的特征明显不明显，明显吧。

所以他能挣到很多很多钱，刘翔的特征明显不明显，跑得快呀，所以他是不是能够挣到很多很多钱，对不对，那我们中国很多运动员是吧，或者说我们身边有一些人，它们的特征也很明显，他们就可以挣到很多钱。

那你的特征是什么呢，比如说你会算法是吧，那这个时候还还不够明显，你得精通算法是吧，你写代码写得又特别好，算法说得头头是道，这叫精通，你这个特征如果足够明显，那么你就可以和这个人群当中的普通人。

怎么样分开，你去找工作是吧，那轻轻松松的是吧，薪资又高是吧，这就是我们持续学习它的价值所在，咱们就是把自己是吧，尽量的离这条边界是吧，远一点，就是说你太耀眼了，别人一看呢就能够看到你。



![](img/1f870c914653d09cacfa80c043aaf02e_15.png)

所以那你还不愁挣不到钱吗，那我们到这儿之后呢，你就能够看到，其实咱们的问题就进行了一个转化是吧。

![](img/1f870c914653d09cacfa80c043aaf02e_17.png)

那我们怎么进行转化的呀，咱们就是根据距离，那其实呢这个中间这条线距离，咱们红色的点有一个距离地，我们希望这个距离越大越好，对不对，我们希望这个距离越大越好，那我们看到这个距离，咱们明白是怎么回事儿了。

那计算我们得需要把我们所理解的，转化成计算机所能理解的，计算机可以理解什么数学公式，那我们就你看这是知识点补充距离的计算，咱们这次就不再赘述了啊。



![](img/1f870c914653d09cacfa80c043aaf02e_19.png)

我们直接往下直接往下看是吧，这个时候呢，它的距离公式经过我们一系列的转化化简。

![](img/1f870c914653d09cacfa80c043aaf02e_21.png)

咱们就可以让上边这条虚线，它的方程就是w t x加b等于一，下边这个就是-1，我们在讲解的时候，咱们是分了两类是吧，咱们逻辑回归在讲解原理的时候，我们是不是也分两类呀。

咱们的支持向量机它也可以进行多分类啊，那么多分类的时候，它其实就是把它转换成了概率问题啊，就是转换成概率问题，由复杂有简单，一点一点到复杂，我们二分类是吧，这个是最简单的，那我们可以衍生是吧。

一点一点把它变成三分类好，那么有了这个距离了，看到了吗。

![](img/1f870c914653d09cacfa80c043aaf02e_23.png)

d9 等于一除以w，那你的w在分母上我们希望它越大越好，看了我们希望它怎么样，是不是希望它越大越好呀对吧，那你w在分母上是不是你的w越小，是不是就越好了，看到了吧，你怎么才能越大呢。

是不是这个w越小呀对吧。

![](img/1f870c914653d09cacfa80c043aaf02e_25.png)

所以说你看这个就转化了，就转化成什么了，看看这个地方的转化啊，是不是就转化了，它等效于最小化1/2 w的平方，你看我们为什么喜欢1/2 w的平方，来表示呢，求导数方便知道吧，这也是数学上的这个规律。

求导数方便我们在写代码的时候，咱们就可以用代码来实现，明白吗，就可以用代码来实现，因为无论我们的数学是吧，是多么高深，或者说数学多么简单，最后我们想要完成一个算法，我们其实是不是都是用代码一行一行。

根据数学原理来一点一点实现的呀，对不对，那所以嗯，我们呢就得充分的利用数学当中的那些规律，你1/2 w的平方是吧，它就不分正负，求导简单。



![](img/1f870c914653d09cacfa80c043aaf02e_27.png)

所以说就采用它了好，那么这个时候呢，你就能够看到我们呢就有了一个嗯，就有了一个优化的方程，就是m2 分之1w让它越小越好，这个时候呢因为是分类问题，我们就有一个约束条件，这个约束条件呢你看到了吧。

哎在这儿呢是吧，我们对于二分类问题，无论你是正的还是负的，你只要和这个方程一相乘，怎么样，大于等于一哎这就说明它就分开了，如果我们找到的这个w，严格的遵守咱们这个方程。

那这就说明啊严格地遵守咱们这个方程，这就说明彻彻底底给分开了，你要注意啊，这个方程此处你看到的是一个线性的，对不对，看到了吧，wt乘以咱们的x加上b，此时看到的是不是一个线性的呀，但是它不一定是线性的。

我们可以通过核函数看看，咱们可以通过核函数把这个方程变成曲线嗯，可以通过核函数把它的这个数据的分布给它，变成咱们的正态分布，是正态分布，那就是有正有负是吧，呃在中间是吧，左中间的左边，中间的右边是吧。

都有一个分布，所以说呢咱们用目标值乘以咱们的方程，它大于等于一，如果要是大于等于一，那就说明严格的分开了，那我们求最小化问题很简单，看求它的最小化可以使用梯度下降，咱们是不是也可以使用这个求导令。

导数等于零呀，对不对，但是现在的问题是什么，看现在的问题是看咱们现在的问题呢，是我们有约束啊，现在的问题是我们有约束。



![](img/1f870c914653d09cacfa80c043aaf02e_29.png)

那有约束该怎么办，看这个时候呢就是拉格朗日乘子了。

![](img/1f870c914653d09cacfa80c043aaf02e_31.png)

还有k k t条件对，有条件是吧，那我们是如何进行转换的。

![](img/1f870c914653d09cacfa80c043aaf02e_33.png)

那在这儿呢我专门写了相应的文章。

![](img/1f870c914653d09cacfa80c043aaf02e_35.png)

这篇文章是介绍咱们拉格朗日乘子法，那拉格朗日乘子法，它要解决的问题就是这种问题是吧，等式约束可以怎么转换是吧，我给它增加一个拉格朗日乘子，然后直接把h x写进去，这个时候是不是就是一个复合的损失函数了。

那这个和上面的是等价的啊，就是下面这个和上面的这个是等价的，因为如果要是有约束的话，看咱们去求解方程不太好求，那你转换成下面这个，它就完全变成了无约束的，这个时候求解就比较简单了。

求导数或者说用梯度下降都可以搞定。

![](img/1f870c914653d09cacfa80c043aaf02e_37.png)

解决这个问题好，那么。

![](img/1f870c914653d09cacfa80c043aaf02e_39.png)

我们在这儿呢直接使用了拉格朗日，橙子的这个拉格朗日乘子法。

![](img/1f870c914653d09cacfa80c043aaf02e_41.png)

它这个公式直接向下写，那为了让大家理解。

![](img/1f870c914653d09cacfa80c043aaf02e_43.png)

我专门写了一篇文章是吧，这篇文章里边儿就详细介绍了，这个拉格朗日乘子它的成立，它的条件是吧，以及呢这个数学上的一些推导。



![](img/1f870c914653d09cacfa80c043aaf02e_45.png)

数学上的一些计算，还有呢就是k k t条件，这个kk t条件呢，是为了进一步解决咱们的方程转换，你能发现你能够发现这个地方是不是有一个，hx小于等于零呀，上面拉格朗日乘子必须得是等号，必须得是等式。

现在是不等式了，还能用吗，拉格朗日乘子法是不是就不能使用了，看到了吧，就不能再使用拉格朗日乘子法了，那怎么办。



![](img/1f870c914653d09cacfa80c043aaf02e_47.png)

兵来将挡，水来土掩是吧，你看松弛变量是吧，加入了松弛变量。

![](img/1f870c914653d09cacfa80c043aaf02e_49.png)

在这儿呢，我又写了一篇文章来介绍这个拉格朗日橙子好，那么这篇文章呢你也仔细看啊，咱们之前上课当中都有介绍，知道吗，之前上课当中都有介绍文章呢。



![](img/1f870c914653d09cacfa80c043aaf02e_51.png)

我也带着你进行了解读，然后转换之后呢，看转换之后上面就是k k d条件。

![](img/1f870c914653d09cacfa80c043aaf02e_53.png)

也就是说你可以转换，你可以将不等式约束是吧，写成咱们拉格朗日乘子法，但是是有条件的是吧，那就是这个条件朗姆达大于等于零。



![](img/1f870c914653d09cacfa80c043aaf02e_55.png)

朗姆达h x等于零是吧，h x小于等于零是吧。

![](img/1f870c914653d09cacfa80c043aaf02e_57.png)

好那么有了这个转化之后呢，那还有问题就是队伍转化，我们所写出来这个方程不太好求是吧，因为里边求最大，里边求最大不太好求。



![](img/1f870c914653d09cacfa80c043aaf02e_59.png)

怎么办，转换一下，我们把它变成是吧，里边求最小值。

![](img/1f870c914653d09cacfa80c043aaf02e_61.png)

外边求最大值，对它进行一个颠倒好。

![](img/1f870c914653d09cacfa80c043aaf02e_63.png)

那么为什么这个对偶它可以这个成立呢是吧。

![](img/1f870c914653d09cacfa80c043aaf02e_65.png)

为什么可以成立呢，唉咱们呢，就以咱们这蓝色的球进行了一个说明是吧。

![](img/1f870c914653d09cacfa80c043aaf02e_67.png)

你看先从左边看看左边是什么，从一堆小的当中是吧，选择最大的，因为你里边是不是先求me呀，里边先求幂是不是比小是吧，从那然后呢外边再来一个max，我们是不是就是从一堆小的当中找最大值呀。

所以说你看就是小小小小小是吧，然后这个右边呢是从一堆大的当中。

![](img/1f870c914653d09cacfa80c043aaf02e_69.png)

你看右边的方程是不是先是max嗯对吧，先求max，先求max，你就找了一个大的，如果还能再找到大的，那么嗯那个再找到的那个大的，那就是咱们这个最优解，然后但是它前面又有一个密。

那这个mean不就是从一堆大的当中找最小的吗，所以说它就是方向的，就是向左，这样的话你左右会师了嗯，咱们是不是就这个刚好就是咱们这个解压是吧，所以说咱们的队友问题转换呢。



![](img/1f870c914653d09cacfa80c043aaf02e_71.png)

也是一个非常巧妙的方法，好那么最后呢我们介绍了这个最小化，咱们的这个svm，它的这个目标函数，那其实就是根据上面咱们讲解的。



![](img/1f870c914653d09cacfa80c043aaf02e_73.png)

1。3当中的这个原理，我们进行的一个推导。

![](img/1f870c914653d09cacfa80c043aaf02e_75.png)

拉格朗日乘子法kk t条件对偶，其实就是咱们1。4，你看咱们1。4呢。

![](img/1f870c914653d09cacfa80c043aaf02e_77.png)

就是嗯最小化s v m的目标函数，然后构造拉格朗日。

![](img/1f870c914653d09cacfa80c043aaf02e_79.png)

然后的话这个k k t条件，然后对它进行这个k a，对他进行拉格朗日乘子法的这个构建。

![](img/1f870c914653d09cacfa80c043aaf02e_81.png)

然后这个是k k t约束条件，然后队友转换。

![](img/1f870c914653d09cacfa80c043aaf02e_83.png)

队友转换之后呢，你看我们把相应的这个数据带进去，咱们是不是就得到这样的一个方程呀，原来我们本来要求w求求b是吧，就是求那个线性方程，或者说求咱们的函数方程，但是这个时候你就发现转换之后。

咱们这里边就只有朗姆达。

![](img/1f870c914653d09cacfa80c043aaf02e_85.png)

那这个拉姆达呢该怎么求呀，看s m o算法它就用来专门制咱们这个方程的。

![](img/1f870c914653d09cacfa80c043aaf02e_87.png)

一看到这个方程，它是有多个朗姆达啊，这个其实没法解，因为方程的数量就不够对吧，方程的数量不够，你看你的约束条件，就这一个lambda lambda i yi等于零是吧，这不够怎么办。



![](img/1f870c914653d09cacfa80c043aaf02e_89.png)

一点一点求这个s mo这个算法是吧，它呢其实就是一种形式的瞎蒙，这种形式的瞎蒙是一种高效的瞎蒙，你知道吗，这是一种高效的瞎蒙是吧，就好比我们电视节目上是吧，有一个商品让咱们的嘉宾猜它的价格，猜对了。

那么你就带走，主持人一般会给你提示，你猜了是吧，668是吧，主持人说低了，你猜了1024，主人说这个主持人说高了，你这时候再猜一个998，主持人就说猜对了，那你是不是就拿走了，对不对。

我们的这个sm算法是吧。

![](img/1f870c914653d09cacfa80c043aaf02e_91.png)

原理上也是类似的，咱们怎么样先求其中的一部分是吧。

![](img/1f870c914653d09cacfa80c043aaf02e_93.png)

我们先先求其中的一部分。

![](img/1f870c914653d09cacfa80c043aaf02e_95.png)

然后它里边呢进行了多次的for循环，嗯最后呢确定了一组啊，最后确定了一组。

![](img/1f870c914653d09cacfa80c043aaf02e_97.png)

所以说呢你看这个就是这个，以便利的形式来找我们答案。

![](img/1f870c914653d09cacfa80c043aaf02e_99.png)

这个就相当于当年这个1997年的时候，ibm的深蓝和卡斯帕罗夫进行国际象棋比比赛，当年之所以深蓝能够赢了卡斯帕罗夫。



![](img/1f870c914653d09cacfa80c043aaf02e_101.png)

就是因为呢这个计算机的计算能力比较强，我对于这个棋谱上的数据一个一个便利是吧。

![](img/1f870c914653d09cacfa80c043aaf02e_103.png)

最后就把它赢了，但是2016年，阿尔法狗和李世石参加比赛的时候是吧，进行对决的时候，那个时候呢和之前相比，就是一个完全不一样的这个算法了，因为围棋比赛是19目乘以19目，他的这个方式比较多。

没有办法穷举，那那个2016年呢就有算法的成分了是吧，就是真正意义上的这个算法之前只是穷举，之前只是比谁快是吧，唉所以说呢到这里呢咱们又将支持向量机。



![](img/1f870c914653d09cacfa80c043aaf02e_105.png)

我们呢过了一遍。

![](img/1f870c914653d09cacfa80c043aaf02e_107.png)

你就发现不是特别难吧，对不对。

![](img/1f870c914653d09cacfa80c043aaf02e_109.png)

当然就这一篇文章是吧，26页写了一周是吧。

![](img/1f870c914653d09cacfa80c043aaf02e_111.png)

这个知识密度比较高，大家呢得把咱们的视频你要多看，你知道我们在一旦写代码的时候，那个代码都比较简单，都是别人封装好的工具，我们站在巨人的肩膀上直接使用，是不是就可以了。



![](img/1f870c914653d09cacfa80c043aaf02e_113.png)

难的是啥呀，你自己能够把这个原理说出来。

![](img/1f870c914653d09cacfa80c043aaf02e_115.png)

变成你自己的这个才行，好，咱们今天晚上呢我们就到这里啊，啊咱们今天的作业呢，我们就这个不留代码，相应的作业了，大家呢把我们知识计算机还有逻辑斯蒂回归，我们总结一下啊，总结一下是吧。

将我们这个线性分类的算法总结一下，我们也上了六次课了，是不是也需要一次总结和回顾好，那么我们今天晚上呢就到这儿啊，好咱们的jerry cosy是吧啊，你在讨论区里边这个问题呢。

咱们在微信里边咱们单独进行沟通啊，今天晚上好，我们就到这里啊，好那我们下课啊。

![](img/1f870c914653d09cacfa80c043aaf02e_117.png)